{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Keras нь өндөр түвшний мэдрэлийн сүлжээний API бөгөөд хэрэглэгчидэд ээлтэй байдал, хурдан загварчилал, модульчилагдсан байдал, өрөгтгөх чөдварт төвлөрдөг. Энэ нь Tensorflow, Theano, CNTK зэрэг гүнзгий сургалтын систимуудтэй ажилууладаг тул бид нейрон сүлжээг асуудалгүй сургах боломжтой."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MNIST нь гараар бичсэн цифрүүдийн 70,000 зургийг агуулдаг: 60,000 нь сургалтанд, 10,000 нь\n",
    "туршилтанд зориулагдсан. Зургууд нь саарал өнгөтэй, 28x28 пикселтэй бөгөөд урьдчилан\n",
    "боловсруулалтыг багасгаж, хурдан эхлүүлэхийн тулд төвлөрсөн байна. Бид хэдэн арван\n",
    "мянган гараар бичсэн зургийн мэдээллийн сангаас цифрүүдийг зөв тодорхойлохыг зорьж"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.trabsforms.RandomRotation(10),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "mnist_train = torchvision.datasets.MNIST('./data', train = True, download = True, transform = )\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('./data', train = False, download = True, transform = )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(mnist_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(mnist_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = mnist_train.data[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.title(mnist_train.targets[0])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Том өгөгдлийн багцтай ажиллахын тулд тэдгээрийг бүгдийг нэг дор санах ойд ачаалах\n",
    "шаардлагатай. Ихэнх тохиолдолд бид системд байгаа санах ойн хэмжээ хязгаарлагдмал тул\n",
    "санах ойн тасалдалтай тулгардаг. Мөн нэг удаа ачаалагдсан хүнд дата багцаас болж\n",
    "програмууд удаан ажиллах хандлагатай байдаг. PyTorch нь DataLoader ашиглан өгөгдөл\n",
    "ачаалах процессыг batch size шийдлийг санал болгодог. Өгөгдлийн ачааллыг параллель\n",
    "болгохын тулд Dataloader ашигласан бөгөөд энэ нь хурдыг нэмэгдүүлж, санах ойг хэмнэдэг.\n",
    "Өгөгдөл ачаалагч бүтээгч нь torch.utils.data багцад байрладаг. Энэ нь янз бүрийн\n",
    "параметрүүдтэй бөгөөд тэдгээрийн хооронд дамжуулагдах ёстой цорын ганц аргумент нь\n",
    "ачаалагдах ёстой өгөгдлийн багц бөгөөд бусад нь бүгд нэмэлт аргументууд юм.\n",
    "Синтакс: DataLoader(dataset, shuffle=True, sampler=None, batch_size=32)\n",
    "Энд датасетийг batch size 1000 ширхэгээр хувааж оруулж байна."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(mnist_train, batch_size = 1000, shuffle = True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = 1000, shuffle = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    print(x[0][0][0][0], y[0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolutional Neural Network үүсгэж байна.\n",
    "\n",
    "max_pool2d: Макс pooling нь дээж дээр суурилсан ялгах үйл явц юм. Зорилго нь оролтын\n",
    "дүрслэлийг (зураг, далд давхаргын гаралтын матриц гэх мэт) доош түүвэрлэн, хэмжээсийг\n",
    "нь багасгаж, давхардсан дэд бүсүүдэд агуулагдах онцлогуудын талаар таамаглал дэвшүүлэх\n",
    "боломжийг олгох явдал юм.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_feature_size = 100):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5) # features extraction\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5) # features extraction\n",
    "        self.fc1 = nn.Linear(320, 100)\n",
    "        self.fc2 = nn.Linear(hidden_feature_size, 10)\n",
    "        self.dp = nn.Dropout2d()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.max_pool2d(self.dp(self.relu(self.conv1(x))),2) # nn.functional gej\n",
    "        x = nn.functional.max_pool2d(self.dp(self.relu(self.conv2(x))),2)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = nn.functional.log_softmax(self.fc2(x), dim = -1)\n",
    "        return x\n",
    "\n",
    "dummy_data = torch.rand(10, 1, 28, 28)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dummy_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = Net()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = net(dummy_data)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. loss.backward()-н дараа optimizer.step()-г дуудаж өгөх хэрэгтэй байдаг учраас\n",
    "zero_grad()-г дууддаг. Бүр тодруулбал, алдагдал.backward() болон optimizer.step() гэсэн\n",
    "хоёр үйлдлийг тусгаарласан ба optimizer.step() нь зөвхөн тооцоолсон градиент\n",
    "шаарддаг тул градиент автоматаар тэглэгддэггүй.\n",
    "\n",
    "2. Loss function-г урьдчилан таамагласан үр дүн болон хүссэн үр дүн хоорондох алдааг\n",
    "хэмжихэд ашигладаг. Loss function нь хүсэж буй үр дүнгээс хэр хол байгааг хэлж өгдөг.\n",
    "\n",
    "3. loss.backward() # бүх параметрийн градиент олдог буюу backpropagation юм.\n",
    "Backpropagation нь хүссэн үр дүн болон гарсан үр дүнгийн хоорондох ялгааг буюу\n",
    "гарсан алдааг багасгахад оршдог. Энэ нь градиент функцийн доошлох чиглэлийн дагуу\n",
    "алдааг тооцоолж явдаг ба хамгийн доор байгаа утга нь хамгийн бага утга байдаг.\n",
    "Дээрээс доошоо тоооцоолдог учир backward гэж бас нэрлэдэг.\n",
    "\n",
    "4. optimizer.step() # бид хамгийн бага алдагдал (алдаа) гаргахын тулд эдгээр\n",
    "параметрүүдийг шинэчилдэг.\n",
    "\n",
    "5. Cross entropy loss алдагдал нь нь 0-ээс 1 хүртэлх тоогоор хэмжигддэг бөгөөд 0 нь төгс\n",
    "загвар юм. Гол зорилго нь загварыг аль болох 0-д ойртуулах явдал юм. Урьдчилан\n",
    "таамагласан магадлал нь бодит тэмдэглэгээнээс зөрөх тусам cross entropy loss нь\n",
    "нэмэгддэг.\n",
    "\n",
    "6. torch.optim.SGD: Implements stochastic gradient descent (optionally with momentum).\n",
    "Optimizer нь neural network-н жин, суралцах хурд зэрэг шинж чанаруудыг өөрчилдөг\n",
    "функц эсвэл алгоритм юм. Тиймээс энэ нь нийт log loss бууруулж, нарийвчлалыг\n",
    "сайжруулахад тусалдаг."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(net, train_loader, test_loader, loss_fn, optimizer, epochs):\n",
    "    net.train()\n",
    "    accurancy = torch.tensor([0.])\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = net(x)\n",
    "        print(preds.shape)\n",
    "        loss = loss_fn(preds, y)\n",
    "        loss.backward() # backprogation, update hiideg\n",
    "        optimizer.step()\n",
    "        print(net.fc2.weight.grad[0][0])\n",
    "        print(net.fc1.weight.grad[0][0])\n",
    "        print(net.conv1.weight.grad[0][0])\n",
    "        print(net.conv2.weight.grad[0][0])\n",
    "        print(loss.item())\n",
    "        break\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.001, momentum = 0.5)\n",
    "epochs = 1\n",
    "train(net, train_loader, test_loader, loss_fn, optimizer, epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(net, train_loader, test_loader, loss_fn, optimizer, epochs):\n",
    "    net.train()\n",
    "    for e in range(epochs):\n",
    "        accuracy = torch.tensor([0.])\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = net(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "            loss.backward() #backpropagation, update hiideg\n",
    "            optimizer.step()\n",
    "            preds = preds.data.max(1, keepdim = True)[1]\n",
    "            accuracy += preds.eq(y.data.view_as(preds)).sum()\n",
    "        print('epochs:', e, 'Accuracy:', accuracy.item()*100/len(mnist_train))\n",
    "        eval(net, test_loader)\n",
    "\n",
    "def eval(net, test_loader):\n",
    "        net.eval()\n",
    "        accuracy = torch.tensor([0])\n",
    "        for x, y in test_loader:\n",
    "            preds = net(x)\n",
    "            preds = preds.data.max(1, keepdim = True)[1]\n",
    "            accuracy += preds.eq(y.data.view_as(preds)).sum()\n",
    "        print(\"test acc:\", accuracy.item()*100/len(mnist_test))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.001, momentum = 0.5)\n",
    "epochs = 2\n",
    "train(net, train_loader, test_loader, loss_fn, optimizer, epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './checkpoints') # model ee hadaglana"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del net # model-ee ustgana"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnn = Net() # shineeer model - ee duudaj ugnu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(cnn, train_loader, test_loader, loss_fn, optimizer, epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnn.load_state_dict(torch.load('./checkpoints')) # hadgalsan model -ee load hiine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(cnn, train_loader, test_loader, loss_fn, optimizer, epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
